# 83RR PowerEdge Infrastructure
# Base Docker Compose configuration for all services
# Auto-loads docker-compose.override.yml for local development
# Use docker-compose.prod.yml for production deployment

# Shared logging configuration to prevent disk space issues
x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

services:
  # ═════════════════════════════════════════════════════════════════════════════
  # NGINX Reverse Proxy
  # ═════════════════════════════════════════════════════════════════════════════
  nginx:
    build:
      context: ./infrastructure/nginx
      dockerfile: Dockerfile
    container_name: nginx
    restart: unless-stopped
    logging: *default-logging
    environment:
      - INFRASTRUCTURE_ENV=${INFRASTRUCTURE_ENV:-production}
    ports:
      - "80:80"
      - "443:443"
      # Note: Minecraft port 25565 added in prod override (docker-compose.prod.yml)
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./infrastructure/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./infrastructure/nginx/certs:/etc/nginx/certs:ro
      # Note: nginx logs go to stdout/stderr (symlinks in Dockerfile) for Docker log capture
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Personal Website (Nuxt.js)
  # ═════════════════════════════════════════════════════════════════════════════
  personal-website:
    build:
      context: ./infrastructure/personal-website/frontend
      dockerfile: Dockerfile
    container_name: personal-website
    restart: unless-stopped
    logging: *default-logging
    environment:
      - NODE_ENV=production
      - NUXT_PUBLIC_API_BASE=/api
      - API_URL=http://flask-api:5000
    networks:
      - infrastructure
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # ═════════════════════════════════════════════════════════════════════════════
  # Cookbook Website (Static Recipe Site)
  # Image published from: github.com/mcheli/cookbook
  # ═════════════════════════════════════════════════════════════════════════════
  cookbook:
    image: ghcr.io/mcheli/cookbook:latest
    container_name: cookbook
    restart: unless-stopped
    logging: *default-logging
    networks:
      - infrastructure
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ═════════════════════════════════════════════════════════════════════════════
  # Flask API Service
  # ═════════════════════════════════════════════════════════════════════════════
  flask-api:
    build:
      context: ./infrastructure/flask-api/backend
      dockerfile: Dockerfile
    container_name: flask-api
    restart: unless-stopped
    logging: *default-logging
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=postgresql://user:pass@postgres:5432/dbname
    networks:
      - infrastructure
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # ═════════════════════════════════════════════════════════════════════════════
  # JupyterHub (Data Science Environment - Multi-User)
  # ═════════════════════════════════════════════════════════════════════════════

  # JupyterHub Proxy (Configurable HTTP Proxy)
  jupyterhub-proxy:
    image: quay.io/jupyterhub/configurable-http-proxy:5
    container_name: jupyterhub-proxy
    restart: unless-stopped
    logging: *default-logging
    command:
      - --ip=0.0.0.0
      - --port=8000
      - --api-ip=0.0.0.0
      - --api-port=8001
      - --default-target=http://jupyterhub:8081
      - --error-target=http://jupyterhub:8081/hub/error
    environment:
      - CONFIGPROXY_AUTH_TOKEN=${CONFIGPROXY_AUTH_TOKEN}
    networks:
      - infrastructure
      - jupyterhub

  # JupyterHub Main Server
  jupyterhub:
    build:
      context: ./infrastructure/jupyter
      dockerfile: Dockerfile
    container_name: jupyterhub
    restart: unless-stopped
    logging: *default-logging
    depends_on:
      - jupyterhub-proxy
      - jupyterhub-db
    environment:
      - CONFIGPROXY_AUTH_TOKEN=${CONFIGPROXY_AUTH_TOKEN}
      - JUPYTER_PASSWORD=${JUPYTER_PASSWORD}
      - ADMIN_USER=${JUPYTER_ADMIN_USER}
      - SINGLEUSER_IMAGE=ghcr.io/mcheli/jupyter:latest
      - TZ=${TZ:-America/New_York}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
    command:
      - /bin/sh
      - -lc
      - |
        set -e

        # Create JupyterHub configuration
        mkdir -p /srv/jupyterhub
        printf '%s\n' \
        "import os" \
        "from dockerspawner import DockerSpawner" \
        "" \
        "c = get_config()" \
        "" \
        "# --- Hub ↔ Proxy networking ---" \
        "c.JupyterHub.bind_url = 'http://:8081'" \
        "c.JupyterHub.hub_bind_url = 'http://:8081'" \
        "c.JupyterHub.hub_connect_url = 'http://jupyterhub:8081'" \
        "c.ConfigurableHTTPProxy.should_start = False" \
        "c.ConfigurableHTTPProxy.api_url = 'http://jupyterhub-proxy:8001'" \
        "c.ConfigurableHTTPProxy.auth_token = os.environ['CONFIGPROXY_AUTH_TOKEN']" \
        "" \
        "# --- Hub DB: Postgres ---" \
        "pw = os.environ.get('POSTGRES_PASSWORD', '')" \
        "c.JupyterHub.db_url = f'postgresql://jhub:{pw}@jupyterhub-db:5432/jhub'" \
        "" \
        "# --- Spawner: each user is a container on same network ---" \
        "c.JupyterHub.spawner_class = DockerSpawner" \
        "c.DockerSpawner.use_internal_ip = True" \
        "c.DockerSpawner.network_name = 'jupyterhub'" \
        "c.DockerSpawner.remove = True" \
        "" \
        "# Use custom pre-built image with all packages and extensions" \
        "c.DockerSpawner.image = os.environ.get('SINGLEUSER_IMAGE', 'ghcr.io/mcheli/jupyter:latest')" \
        "" \
        "# Resource limits and user environment" \
        "c.DockerSpawner.mem_limit = '4G'" \
        "c.DockerSpawner.cpu_limit = 2.0" \
        "c.DockerSpawner.volumes = {" \
        "    'jupyterhub-user-{username}': '/home/jovyan'," \
        "    'jupyterhub-shared': {'bind': '/home/jovyan/shared', 'mode': 'rw'}" \
        "}" \
        "c.DockerSpawner.notebook_dir = '/home/jovyan'" \
        "c.Spawner.default_url = '/lab'" \
        "" \
        "# Enhanced environment variables" \
        'c.Spawner.environment = {' \
        '    "TZ": os.environ.get("TZ", "America/New_York"),' \
        '    "JUPYTERHUB_SINGLEUSER_APP": "jupyter_server.serverapp.ServerApp",' \
        '    "JUPYTER_ENABLE_LAB": "yes",' \
        '    "CHOWN_HOME": "yes",' \
        '    "CHOWN_HOME_OPTS": "-R",' \
        '    "OPENAI_API_KEY": os.environ.get("OPENAI_API_KEY", ""),' \
        '    "ANTHROPIC_API_KEY": os.environ.get("ANTHROPIC_API_KEY", "")' \
        '}' \
        "" \
        "# Extended timeouts for package installation" \
        "c.Spawner.http_timeout = 600" \
        "c.Spawner.start_timeout = 600" \
        "" \
        "# --- Auth: Simple password authentication ---" \
        "c.JupyterHub.authenticator_class = 'jupyterhub.auth.DummyAuthenticator'" \
        "c.DummyAuthenticator.password = os.environ['JUPYTER_PASSWORD']" \
        "admin_user = os.environ.get('ADMIN_USER')" \
        "if admin_user:" \
        "    c.Authenticator.admin_users = {admin_user}" \
        "" \
        "# --- Idle culler service ---" \
        "c.JupyterHub.services = [" \
        "    {" \
        "        'name': 'idle-culler'," \
        "        'admin': True," \
        "        'command': [" \
        "            'python3', '-m', 'jupyterhub_idle_culler'," \
        "            '--timeout=7200'," \
        "            '--cull-every=600'," \
        "            '--concurrency=10'," \
        "            '--max-age=0'" \
        "        ]," \
        "    }" \
        "]" \
        "" \
        "# Service permissions" \
        "c.JupyterHub.load_roles = [" \
        "    {" \
        "        'name': 'idle-culler-role'," \
        "        'scopes': ['list:users', 'read:users:activity', 'servers', 'delete:servers']," \
        "        'services': ['idle-culler']," \
        "    }" \
        "]" \
        > /srv/jupyterhub/jupyterhub_config.py

        # Install JupyterHub dependencies
        pip install --no-cache-dir \
          'dockerspawner>=13.0.0' \
          'jupyterlab>=4.0.0' \
          'notebook' \
          'docker' \
          'jupyterhub-idle-culler' \
          'psycopg2-binary'

        exec jupyterhub -f /srv/jupyterhub/jupyterhub_config.py
    volumes:
      - jupyterhub_data:/srv/jupyterhub
      - jupyterhub_shared:/srv/shared
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - infrastructure
      - jupyterhub

  # PostgreSQL Database for JupyterHub
  jupyterhub-db:
    image: postgres:16-alpine
    container_name: jupyterhub-db
    restart: unless-stopped
    logging: *default-logging
    environment:
      - POSTGRES_DB=jhub
      - POSTGRES_USER=jhub
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - jupyterhub_db_data:/var/lib/postgresql/data
    networks:
      - jupyterhub
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U jhub -d jhub"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ═════════════════════════════════════════════════════════════════════════════
  # OpenSearch (Logging Infrastructure)
  # Note: Using 'latest' because data format requires matching version; pin after fresh install
  # ═════════════════════════════════════════════════════════════════════════════
  opensearch:
    image: opensearchproject/opensearch:2.19.0  # Pinned for security
    container_name: opensearch
    restart: unless-stopped
    logging: *default-logging
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node1
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - "DISABLE_INSTALL_DEMO_CONFIG=true"
      - "DISABLE_SECURITY_PLUGIN=true"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"\\|\"status\":\"yellow\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # OpenSearch Dashboards (Logging UI)
  # ═════════════════════════════════════════════════════════════════════════════
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.19.0  # Match OpenSearch version
    container_name: opensearch-dashboards
    restart: unless-stopped
    logging: *default-logging
    environment:
      - OPENSEARCH_HOSTS=http://opensearch:9200
      - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true"
    depends_on:
      - opensearch
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:5601/api/status | grep -q 'available'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Fluent Bit (Log Shipper)
  # ═════════════════════════════════════════════════════════════════════════════
  fluent-bit:
    image: fluent/fluent-bit:3.2
    container_name: fluent-bit
    restart: unless-stopped
    logging: *default-logging
    user: root
    volumes:
      - ./infrastructure/fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./infrastructure/fluent-bit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - ./infrastructure/fluent-bit/docker_metadata.lua:/fluent-bit/etc/docker_metadata.lua:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - fluent_bit_data:/var/log
      - plex_config:/plex-logs:ro
      - /storage/seafile/seafile/logs:/seafile-logs:ro
    depends_on:
      - opensearch
    # Note: Fluent Bit distroless image has no shell utilities for health checks
    # Service health can be verified via: docker logs fluent-bit | grep -i error
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Minecraft Server
  # ═════════════════════════════════════════════════════════════════════════════
  minecraft:
    image: itzg/minecraft-server:java21
    container_name: minecraft
    restart: unless-stopped
    logging: *default-logging
    environment:
      - EULA=TRUE
      - TYPE=PAPER
      - VERSION=LATEST
      - MEMORY=2G
      - DIFFICULTY=normal
      - MOTD="83RR PowerEdge Minecraft Server"
      - ENABLE_WHITELIST=false
    volumes:
      - minecraft_data:/data
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Monitoring: Prometheus (Metrics Database)
  # ═════════════════════════════════════════════════════════════════════════════
  prometheus:
    image: prom/prometheus:v3.2.1
    container_name: prometheus
    restart: unless-stopped
    logging: *default-logging
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=30d'
    volumes:
      - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Monitoring: Grafana (Visualization Dashboards)
  # ═════════════════════════════════════════════════════════════════════════════
  grafana:
    image: grafana/grafana:11.5.2
    container_name: grafana
    restart: unless-stopped
    logging: *default-logging
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./infrastructure/monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Monitoring: cAdvisor (Container Metrics)
  # ═════════════════════════════════════════════════════════════════════════════
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.52.1
    container_name: cadvisor
    restart: unless-stopped
    logging: *default-logging
    user: "0"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Monitoring: NGINX Exporter (NGINX Metrics)
  # ═════════════════════════════════════════════════════════════════════════════
  nginx-exporter:
    image: nginx/nginx-prometheus-exporter:1.4
    container_name: nginx-exporter
    restart: unless-stopped
    logging: *default-logging
    command:
      - '--nginx.scrape-uri=http://nginx:80/nginx_status'
    depends_on:
      - nginx
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Monitoring: Node Exporter (Host System Metrics)
  # ═════════════════════════════════════════════════════════════════════════════
  node-exporter:
    image: prom/node-exporter:v1.8.2
    container_name: node-exporter
    restart: unless-stopped
    logging: *default-logging
    command:
      - '--path.rootfs=/host'
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    pid: host
    volumes:
      - '/:/host:ro,rslave'
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9100/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - infrastructure

# ═════════════════════════════════════════════════════════════════════════════
  # Plex Media Server
  # ═════════════════════════════════════════════════════════════════════════════
  plex:
    image: plexinc/pms-docker:1.41.3  # Pinned for security
    container_name: plex
    restart: unless-stopped
    logging: *default-logging
    environment:
      - TZ=America/New_York
      - PLEX_CLAIM=${PLEX_CLAIM:-}
    ports:
      - "32400:32400"
      - "1900:1900/udp"
      - "32469:32469"
      - "5353:5353/udp"
    volumes:
      - plex_config:/config
      - /storage/media:/data:ro
    networks:
      - infrastructure

  # ═════════════════════════════════════════════════════════════════════════════
  # Seafile (Dropbox Replacement)
  # ═════════════════════════════════════════════════════════════════════════════
  seafile-db:
    image: mariadb:10.11
    container_name: seafile-db
    restart: unless-stopped
    logging: *default-logging
    environment:
      - MYSQL_ROOT_PASSWORD=${SEAFILE_DB_ROOT_PASSWORD}
      - MYSQL_LOG_CONSOLE=true
    volumes:
      - seafile_db:/var/lib/mysql
    networks:
      - infrastructure

  seafile-memcached:
    image: memcached:1.6
    container_name: seafile-memcached
    restart: unless-stopped
    logging: *default-logging
    entrypoint: memcached -m 256
    networks:
      - infrastructure

  seafile:
    image: seafileltd/seafile-mc:11.0.13  # Pinned for security
    container_name: seafile
    restart: unless-stopped
    logging: *default-logging
    depends_on:
      - seafile-db
      - seafile-memcached
    environment:
      - DB_HOST=seafile-db
      - DB_ROOT_PASSWD=${SEAFILE_DB_ROOT_PASSWORD}
      - SEAFILE_ADMIN_EMAIL=${SEAFILE_ADMIN_EMAIL}
      - SEAFILE_ADMIN_PASSWORD=${SEAFILE_ADMIN_PASSWORD}
      - SEAFILE_SERVER_HOSTNAME=files.markcheli.com
      - SEAFILE_SERVER_LETSENCRYPT=false
      - SEAFILE_SERVICE_URL=https://files.markcheli.com
      - SEAFILE_FILE_SERVER_ROOT=https://files.markcheli.com/seafhttp
    volumes:
      - /storage/seafile:/shared
    networks:
      - infrastructure

# ═════════════════════════════════════════════════════════════════════════════
# Networks
# ═════════════════════════════════════════════════════════════════════════════
networks:
  infrastructure:
    driver: bridge
  jupyterhub:
    name: jupyterhub
    driver: bridge

# ═════════════════════════════════════════════════════════════════════════════
# Volumes
# ═════════════════════════════════════════════════════════════════════════════
volumes:
  jupyterhub_data:
  jupyterhub_shared:
  jupyterhub_db_data:
  opensearch_data:
  fluent_bit_data:
  minecraft_data:
  prometheus_data:
  grafana_data:
  plex_config:
  seafile_db: